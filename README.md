# GeSIM-Bot
<img src="https://raw.githubusercontent.com/github/explore/main/topics/twitter/twitter.png" width="28"/> GeSIM Twitter Bot (Node.js)
Your crypto-native travel & conference co-pilot â€” powered by LLMs & real-time Twitter mentions
<p align="center"> <img src="https://img.shields.io/badge/Node.js-18+-green?style=flat-square" /> <img src="https://img.shields.io/badge/Prisma-ORM-blue?style=flat-square" /> <img src="https://img.shields.io/badge/Twitter%20API-v2-lightblue?style=flat-square" /> <img src="https://img.shields.io/badge/OpenAI-LLM-orange?style=flat-square" /> <img src="https://img.shields.io/badge/Status-Active-success?style=flat-square" /> <img src="https://img.shields.io/badge/License-MIT-purple?style=flat-square" /> </p>
âœ¨ Overview
The GeSIM Twitter Bot is a crypto-native AI assistant built to help conference attendees discover events, afterparties, meetups, and curated itineraries â€” purely by mentioning @GeSIM_AI on Twitter (X).
This bot:
Reads event data only from your Postgres DB (via Prisma)
Auto-replies to mentions with top 4 featured events
Filters events via keywords (e.g., De-Fi, Gaming, De-Pin)
Generates LLM-powered threads when users ask for â€œplanâ€, â€œitineraryâ€, or â€œwhat should I do?â€
Is fully extendable â€” supports side events, weather, CTAs, deep threads, and more
ğŸš€ Features
ğŸ—‚ï¸ Database-Driven
All events come from the local Postgres DB. No scraping. No external feeds.
ğŸ’¬ Mention-Based Replies
User tweets:
@GeSIM_AI DEVCONNECT What events tonight?
Bot replies:
Top 4 curated events
With time & venue
CTA
ğŸ·ï¸ Keyword Filtering
User replies:
Gaming
Bot replies with events tagged Gaming from DB.
ğŸ§µ LLM Thread Generator
For queries like:
@GeSIM_AI what's the plan for DEVCONNECT if I want a marketing job?
Bot builds:
A structured thread (5â€“6 tweets)
Action steps
Networking scripts
CTA with $GSM
ğŸ” Safe & Guardrailed
No hallucinated events (DB-only)
Sanitized replies (no PII, no unsafe content)
Optional rate-limiting + signature verification
ğŸ—ï¸ Architecture
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   Mention @GeSIM_AI â”‚   Twitter Webhook (X)    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  /webhook/twitter        â”‚               â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
                                     â”‚                          â”‚
                                     â–¼                          â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
                         â”‚   mentionHandler     â”‚                â”‚
                         â”‚  parse + route       â”‚                â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
                                    â”‚                            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           Services                         â”‚
    â”‚                                                            â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚    â”‚  dbService     â”‚   â”‚ llmService     â”‚   â”‚ twitterSvc â”‚ â”‚
    â”‚    â”‚ Prisma/Postgresâ”‚   â”‚ OpenAI Threads â”‚   â”‚ Reply/Threadâ”‚ â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                      â”‚                 â”‚
                 â–¼                      â–¼                 â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Events DB  â”‚        â”‚ LLM Reply   â”‚    â”‚ Tweets API â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸ“¦ Installation & Setup
1. Clone repo
git clone https://github.com/<your-org>/gesim-twitter-bot.git
cd gesim-twitter-bot
2. Copy environment variables
cp .env.example .env
Fill in:
Twitter API keys
OpenAI API key
DATABASE_URL
WEBHOOK_CONSUMER_SECRET
3. Install dependencies
npm install
4. Generate Prisma client
npx prisma generate
5. Run migrations
npx prisma migrate dev --name init
6. Seed sample data
npm run seed
7. Run dev server
npm run dev
Server runs at:
http://localhost:8080
ğŸŒ Webhook Setup (Twitter/X)
To receive mentions in real time:
1. Start ngrok
ngrok http 8080
2. Add webhook URL in Twitter Developer Portal
Example:
https://your-ngrok-url.ngrok-free.app/webhook/twitter
3. Validate CRC challenge
Twitter will call:
GET /webhook/twitter?crc_token=xxxx
Your bot automatically responds with sha256= signature.
4. Subscribe the bot account to the webhook
(using Account Activity API)
ğŸ’¡ Environment Variables
Variable	Description
TW_APP_KEY	Twitter App Key
TW_APP_SECRET	Twitter App Secret
TW_ACCESS_TOKEN	Twitter Access Token
TW_ACCESS_SECRET	Twitter Access Secret
WEBHOOK_CONSUMER_SECRET	CRC secret for webhook validation
OPENAI_API_KEY	OpenAI key
DATABASE_URL	Postgres connection string
BOT_TWITTER_HANDLE	Bot username (e.g., GeSIM_AI)
FEATURED_LIMIT	# of events to show (default: 4)
ğŸ¯ How Replies Work
Public Mention â†’ Short Reply
Extract conference slug (e.g., DEVCONNECT)
Fetch events from DB
Generate LLM short response
Post via reply to original tweet
Keyword Reply
User replies:
De-Pin
Bot filters tags in DB â†’ replies again.
Thread Request
Detected via words:
plan
itinerary
thread
job
how should I
LLM generates multi-tweet thread.
ğŸ¤– Models & LLM Prompts
Default model: gpt-4o-mini
Fully customizable in services/llmService.js
Includes:
Persona
Short reply prompt
Thread generation prompt
Safety constraints
ğŸ›¡ï¸ Production Recommendations
âœ” Add Redis rate-limiting
âœ” Add Twitter signature verification
âœ” Add Sentry logging
âœ” Add BullMQ for posting tweets safely
âœ” Use Docker for deployment
âœ” Rotate API keys frequently
ğŸ§ª Testing
Local webhook simulation:
node test.js
ğŸ“„ License
MIT Â© 2025 GeSIM